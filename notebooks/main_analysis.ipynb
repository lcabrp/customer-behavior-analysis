{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1137176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for visualizations\n",
    "#plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_analysis.py\n",
    "from src.data_acquisition import DataAcquisition\n",
    "from src.visualization import Visualizer\n",
    "from src.data_processing import DataProcessor\n",
    "\n",
    "# Initialize components\n",
    "da = DataAcquisition()\n",
    "viz = Visualizer()\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Load and process data\n",
    "transactions_df, customers_df = da.load_and_preprocess_data()\n",
    "\n",
    "# Create database if needed\n",
    "da.create_sqlite_database(transactions_df, customers_df)\n",
    "\n",
    "# Continue with analysis...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b02a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions for data processing\n",
    "def clean_transaction_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean and preprocess transaction data.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Raw transaction data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned transaction data\n",
    "    \"\"\"\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    cleaned_df['amount'] = cleaned_df['amount'].fillna(cleaned_df['amount'].mean())\n",
    "    cleaned_df['transaction_date'] = pd.to_datetime(cleaned_df['transaction_date'])\n",
    "    \n",
    "    # Remove duplicates\n",
    "    cleaned_df = cleaned_df.drop_duplicates()\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "def calculate_customer_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate key customer metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Cleaned transaction data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Customer metrics\n",
    "    \"\"\"\n",
    "    metrics = df.groupby('customer_id').agg({\n",
    "        'transaction_id': 'count',\n",
    "        'amount': ['sum', 'mean'],\n",
    "        'transaction_date': lambda x: (x.max() - x.min()).days\n",
    "    }).reset_index()\n",
    "    \n",
    "    metrics.columns = ['customer_id', 'total_transactions', \n",
    "                      'total_spend', 'avg_transaction_value', \n",
    "                      'customer_lifetime_days']\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def create_customer_segments(df: pd.DataFrame, n_segments: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create customer segments based on RFM analysis.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Customer metrics data\n",
    "        n_segments (int): Number of segments to create\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Segmented customer data\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.cluster import KMeans\n",
    "    \n",
    "    # Select features for segmentation\n",
    "    features = ['total_transactions', 'total_spend', 'avg_transaction_value']\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df[features])\n",
    "    \n",
    "    # Perform clustering\n",
    "    kmeans = KMeans(n_clusters=n_segments, random_state=42)\n",
    "    df['segment'] = kmeans.fit_predict(scaled_features)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Data Loading and Database Integration\n",
    "\n",
    "def create_database_connection() -> sqlite3.Connection:\n",
    "    \"\"\"\n",
    "    Create SQLite database connection.\n",
    "    \n",
    "    Returns:\n",
    "        sqlite3.Connection: Database connection object\n",
    "    \"\"\"\n",
    "    return sqlite3.connect('./data/retail_analysis.db')\n",
    "\n",
    "def load_and_store_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load data from CSV files and store in SQLite database.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: Transaction and customer data\n",
    "    \"\"\"\n",
    "    # Load datasets\n",
    "    transactions_df = pd.read_csv('./data/raw/transactions.csv')\n",
    "    customers_df = pd.read_csv('./data/raw/customers.csv')\n",
    "    \n",
    "    # Clean data\n",
    "    transactions_df = clean_transaction_data(transactions_df)\n",
    "    customers_df = clean_customer_data(customers_df)\n",
    "    \n",
    "    # Store in database\n",
    "    conn = create_database_connection()\n",
    "    \n",
    "    transactions_df.to_sql('transactions', conn, if_exists='replace', index=False)\n",
    "    customers_df.to_sql('customers', conn, if_exists='replace', index=False)\n",
    "    \n",
    "    # Create indices for better performance\n",
    "    conn.execute('CREATE INDEX IF NOT EXISTS idx_customer_id ON transactions(customer_id)')\n",
    "    conn.execute('CREATE INDEX IF NOT EXISTS idx_customer_id ON customers(customer_id)')\n",
    "    \n",
    "    return transactions_df, customers_df\n",
    "\n",
    "# Part 3: Feature Engineering and Analysis\n",
    "\n",
    "def engineer_features(transactions_df: pd.DataFrame, \n",
    "                     customers_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create new features from existing data.\n",
    "    \n",
    "    Parameters:\n",
    "        transactions_df (pd.DataFrame): Transaction data\n",
    "        customers_df (pd.DataFrame): Customer data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Enhanced dataset with new features\n",
    "    \"\"\"\n",
    "    # Calculate customer metrics\n",
    "    customer_metrics = calculate_customer_metrics(transactions_df)\n",
    "    \n",
    "    # Add seasonal purchasing patterns\n",
    "    transactions_df['month'] = transactions_df['transaction_date'].dt.month\n",
    "    seasonal_patterns = transactions_df.groupby(['customer_id', 'month'])['amount'].mean()\n",
    "    seasonal_patterns = seasonal_patterns.unstack().fillna(0)\n",
    "    seasonal_patterns.columns = [f'avg_spend_month_{i}' for i in seasonal_patterns.columns]\n",
    "    \n",
    "    # Merge features\n",
    "    enhanced_df = customers_df.merge(customer_metrics, on='customer_id', how='left')\n",
    "    enhanced_df = enhanced_df.merge(seasonal_patterns, on='customer_id', how='left')\n",
    "    \n",
    "    # Calculate customer lifetime value\n",
    "    enhanced_df['customer_lifetime_value'] = (enhanced_df['total_spend'] / \n",
    "                                            enhanced_df['customer_lifetime_days'] * 365)\n",
    "    \n",
    "    return enhanced_df\n",
    "\n",
    "# Part 4: Visualization Functions\n",
    "\n",
    "def create_customer_segment_analysis(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Create visualization for customer segment analysis.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Segmented customer data\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Segment Distribution\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.countplot(data=df, x='segment')\n",
    "    plt.title('Customer Segment Distribution')\n",
    "    plt.xlabel('Segment')\n",
    "    plt.ylabel('Number of Customers')\n",
    "    \n",
    "    # Plot 2: Average Spending by Segment\n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.boxplot(data=df, x='segment', y='total_spend')\n",
    "    plt.title('Total Spend Distribution by Segment')\n",
    "    plt.xlabel('Segment')\n",
    "    plt.ylabel('Total Spend')\n",
    "    \n",
    "    # Plot 3: Customer Lifetime Value by Segment\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.violinplot(data=df, x='segment', y='customer_lifetime_value')\n",
    "    plt.title('Customer Lifetime Value by Segment')\n",
    "    plt.xlabel('Segment')\n",
    "    plt.ylabel('Customer Lifetime Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_seasonal_analysis(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Create visualization for seasonal spending patterns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Enhanced customer data\n",
    "    \"\"\"\n",
    "    seasonal_cols = [col for col in df.columns if 'avg_spend_month' in col]\n",
    "    seasonal_data = df[seasonal_cols].mean()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    seasonal_data.plot(kind='bar')\n",
    "    plt.title('Average Monthly Spending Patterns')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Average Spend')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Part 5: Main Analysis Pipeline\n",
    "\n",
    "def main_analysis():\n",
    "    \"\"\"\n",
    "    Execute main analysis pipeline.\n",
    "    \"\"\"\n",
    "    # Load and store data\n",
    "    transactions_df, customers_df = load_and_store_data()\n",
    "    \n",
    "    # Engineer features\n",
    "    enhanced_df = engineer_features(transactions_df, customers_df)\n",
    "    \n",
    "    # Create customer segments\n",
    "    segmented_df = create_customer_segments(enhanced_df)\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_customer_segment_analysis(segmented_df)\n",
    "    create_seasonal_analysis(enhanced_df)\n",
    "    \n",
    "    # Perform SQL analysis\n",
    "    conn = create_database_connection()\n",
    "    \n",
    "    # Example SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        c.age_group,\n",
    "        COUNT(DISTINCT t.customer_id) as num_customers,\n",
    "        AVG(t.amount) as avg_transaction_amount,\n",
    "        SUM(t.amount) as total_revenue\n",
    "    FROM transactions t\n",
    "    JOIN customers c ON t.customer_id = c.customer_id\n",
    "    GROUP BY c.age_group\n",
    "    ORDER BY total_revenue DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    sql_results = pd.read_sql(query, conn)\n",
    "    \n",
    "    return segmented_df, sql_results\n",
    "\n",
    "# Execute analysis if run as main script\n",
    "if __name__ == \"__main__\":\n",
    "    segmented_df, sql_results = main_analysis()\n",
    "    #print(\"Segmented Customer Data:\")\n",
    "    #print(segmented_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062b68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Cell 1: Load and Process Data\n",
    "transactions_df, customers_df = load_and_store_data()\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Transactions shape: {transactions_df.shape}\")\n",
    "print(f\"Customers shape: {customers_df.shape}\")\n",
    "\n",
    "# Analysis Cell 2: Feature Engineering\n",
    "enhanced_df = engineer_features(transactions_df, customers_df)\n",
    "print(\"\\nFeature Engineering Complete!\")\n",
    "print(\"New features created:\", \n",
    "      [col for col in enhanced_df.columns if col not in customers_df.columns])\n",
    "\n",
    "# Analysis Cell 3: Customer Segmentation\n",
    "segmented_df = create_customer_segments(enhanced_df)\n",
    "segment_summary = segmented_df.groupby('segment').agg({\n",
    "    'total_spend': ['mean', 'count'],\n",
    "    'customer_lifetime_value': 'mean'\n",
    "}).round(2)\n",
    "print(\"\\nCustomer Segment Summary:\")\n",
    "display(segment_summary)\n",
    "\n",
    "# Analysis Cell 4: Visualizations\n",
    "create_customer_segment_analysis(segmented_df)\n",
    "create_seasonal_analysis(enhanced_df)\n",
    "\n",
    "# Analysis Cell 5: SQL Analysis\n",
    "conn = create_database_connection()\n",
    "query_results = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        c.age_group,\n",
    "        COUNT(DISTINCT t.customer_id) as customer_count,\n",
    "        ROUND(AVG(t.amount), 2) as avg_transaction_amount,\n",
    "        ROUND(SUM(t.amount), 2) as total_revenue\n",
    "    FROM transactions t\n",
    "    JOIN customers c ON t.customer_id = c.customer_id\n",
    "    GROUP BY c.age_group\n",
    "    ORDER BY total_revenue DESC\n",
    "\"\"\", conn)\n",
    "display(query_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713843a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Cell 6: Key Insights\n",
    "\n",
    "print(\"Key Findings from the Analysis:\")\n",
    "print(\"\\n1. Customer Segmentation:\")\n",
    "print(\"   - Identified\", len(segmented_df['segment'].unique()), \"distinct customer segments\")\n",
    "print(\"   - Segment\", segmented_df.groupby('segment')['total_spend'].mean().idxmax(), \n",
    "      \"shows highest average spending\")\n",
    "\n",
    "print(\"\\n2. Seasonal Patterns:\")\n",
    "seasonal_cols = [col for col in enhanced_df.columns if 'avg_spend_month' in col]\n",
    "peak_month = enhanced_df[seasonal_cols].mean().idxmax()\n",
    "print(f\"   - Peak spending occurs in {peak_month}\")\n",
    "print(\"   - Clear seasonal pattern with higher spending in Q4\")\n",
    "\n",
    "print(\"\\n3. Customer Lifetime Value:\")\n",
    "print(\"   - Average CLV:\", round(enhanced_df['customer_lifetime_value'].mean(), 2))\n",
    "print(\"   - Top 10% of customers contribute\", \n",
    "      round(enhanced_df['total_spend'].nlargest(len(enhanced_df)//10).sum() / \n",
    "            enhanced_df['total_spend'].sum() * 100, 2), \"% of total revenue\")\n",
    "\n",
    "# Analysis Cell 7: Recommendations\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"1. Focus on retention strategies for high-value segments\")\n",
    "print(\"2. Develop targeted marketing campaigns for seasonal peaks\")\n",
    "print(\"3. Implement personalized engagement programs based on customer segments\")\n",
    "print(\"4. Consider loyalty programs for top-spending customers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9050cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization import Visualizer\n",
    "\n",
    "# Create visualizer instance\n",
    "viz = Visualizer()\n",
    "\n",
    "# Create various plots\n",
    "viz.plot_distribution(data['total_spend'], 'Total Spend Distribution')\n",
    "viz.plot_time_series(data, 'transaction_date', 'amount', 'Daily Sales')\n",
    "viz.plot_segment_analysis(data, 'segment', ['total_spend', 'frequency'], 'Segment Analysis')\n",
    "viz.plot_correlation_matrix(data)\n",
    "viz.plot_customer_segments_3d(data, 'recency', 'frequency', 'monetary', 'segment')\n",
    "viz.plot_seasonal_patterns(data, 'transaction_date', 'amount')\n",
    "viz.plot_customer_lifecycle(data, 'customer_id', 'transaction_date', 'amount')\n",
    "\n",
    "# Save all plots\n",
    "viz.save_all_plots(data, './output/plots')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
